{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pgmpy.estimators import BdeuScore, K2Score, BicScore\n",
    "from pgmpy.models import BayesianModel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute, MatrixFactorization, IterativeSVD, BiScaler\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier, CatBoost, CatBoostRegressor\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pomegranate import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simulation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sim_dataset(test, validation, n_samples, n_rows,  n_sets):\n",
    "    \n",
    "#     test = pd.read_csv(\"../data/test_kor.csv\")\n",
    "    frame = ~test.isna()\n",
    "    \n",
    "    validation = validation.reindex(frame.columns, axis=1)\n",
    "    \n",
    "    result_lst = []\n",
    "    \n",
    "    for _ in range(n_sets):\n",
    "\n",
    "        validation_sampled = validation.sample(n=n_samples, replace=False)\n",
    "\n",
    "        n_split = n_samples / n_rows\n",
    "\n",
    "        splited_indexes = np.array_split(validation_sampled.index, n_split)\n",
    "\n",
    "        problem_df_lst = []\n",
    "        answer_df_lst = []\n",
    "        for idx in splited_indexes:\n",
    "            selected_df = validation.loc[idx]\n",
    "            selected_df.reset_index(drop=True, inplace=True)\n",
    "            problem_df_lst.append(selected_df[frame])\n",
    "            answer_df_lst.append(selected_df)\n",
    "\n",
    "        problem_df = pd.concat(problem_df_lst)\n",
    "        answer_df = pd.concat(answer_df_lst)\n",
    "        result_lst.append({\n",
    "            'problem': problem_df, \n",
    "            'answer': answer_df\n",
    "                           \n",
    "        })\n",
    "    return result_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metric for scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_numerical_score(pred_df, true_df, B,  sj=1):\n",
    "    diff = np.concatenate(pred_df[numeric_predictor].values - true_df[numeric_predictor].values)\n",
    "    diff = diff[~np.isnan(diff)]\n",
    "    return B * np.sum(np.exp(-((diff/sj) ** 2)))\n",
    "\n",
    "def calculate_categorical_score(pred_df, true_df, C):\n",
    "    return C * np.sum(pred_df[categorical_predictor].values == true_df[categorical_predictor].values)\n",
    "\n",
    "def calculate_total_score(pred_df, true_df, sj, B, C):\n",
    "    \n",
    "    return calculate_numerical_score(pred_df, true_df, B=B, sj=sj) + calculate_categorical_score(pred_df, true_df, C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_dummy(df_dummies):\n",
    "    pos = defaultdict(list)\n",
    "    vals = defaultdict(list)\n",
    "\n",
    "    for i, c in enumerate(df_dummies.columns):\n",
    "        if \"_\" in c:\n",
    "            k, v = c.split(\"_\", 1)\n",
    "            pos[k].append(i)\n",
    "            vals[k].append(v)\n",
    "        else:\n",
    "            pos[\"_\"].append(i)\n",
    "\n",
    "    df = pd.DataFrame({k: pd.Categorical.from_codes(\n",
    "                              np.argmax(df_dummies.iloc[:, pos[k]].values, axis=1),\n",
    "                              vals[k])\n",
    "                      for k in vals})\n",
    "\n",
    "    df[df_dummies.columns[pos[\"_\"]]] = df_dummies.iloc[:, pos[\"_\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_mapping_set(df):\n",
    "    cat_mapping_set = {}\n",
    "    col_names = df.columns\n",
    "    for col_name in col_names:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        result = le.fit(df[col_name])    \n",
    "        cat_mapping_set[col_name] = le\n",
    "    \n",
    "    return cat_mapping_set\n",
    "\n",
    "def encode_df(df, cat_mapping_set):\n",
    "    tmp_dic_lst = []\n",
    "    col_names = df.columns\n",
    "    for col_name in col_names:\n",
    "        tmp_dic_lst.append(cat_mapping_set[col_name].transform(df[col_name]))\n",
    "    tmp_dic_lst = np.array(tmp_dic_lst)    \n",
    "    combined_df_encoded = pd.DataFrame(np.matrix(tmp_dic_lst.T), columns=col_names)\n",
    "    return combined_df_encoded\n",
    "\n",
    "def decode_df(df, cat_col_names, cat_mapping_set):\n",
    "    tmp_dic_lst2 = []\n",
    "    for col_name in cat_col_names:\n",
    "        tmp_dic_lst2.append([cat_mapping_set[col_name].inverse_transform(df[col_name])])\n",
    "    tmp_dic_lst2 = np.array(tmp_dic_lst2)  \n",
    "    combined_df_decoded = pd.DataFrame(np.matrix(tmp_dic_lst2.T), columns=cat_col_names) \n",
    "    return combined_df_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problem(type_q, row):\n",
    "    tmp = []\n",
    "    for idx in range(len(row)):\n",
    "        if idx in type_q:\n",
    "            tmp.append(None)\n",
    "        else:\n",
    "            tmp.append(row[idx])\n",
    "    tmp = np.array(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download file from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(filenames):\n",
    "    \n",
    "    import boto3\n",
    "    import botocore\n",
    "    \n",
    "    s3 = boto3.resource('s3')\n",
    "    \n",
    "    BUCKET_NAME = 'kaj011'\n",
    "    \n",
    "    for filename in filenames:\n",
    "        KEY = 'samsung_challenge/%s' % filename\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            s3.Bucket(BUCKET_NAME).download_file(KEY, '../data/%s' % filename)\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == \"404\":\n",
    "                print(\"The object does not exist.\")\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
