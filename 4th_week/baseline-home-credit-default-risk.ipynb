{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "train = pd.read_csv(\"4th_week/data/application_train.csv\")\n",
    "test = pd.read_csv(\"4th_week/data/application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FLAG_SUM = train[['FLAG_DOCUMENT_2',\n",
    "                        'FLAG_DOCUMENT_3',\n",
    "                        'FLAG_DOCUMENT_4',\n",
    "                        'FLAG_DOCUMENT_5',\n",
    "                        'FLAG_DOCUMENT_6',\n",
    "                        'FLAG_DOCUMENT_7',\n",
    "                        'FLAG_DOCUMENT_8',\n",
    "                        'FLAG_DOCUMENT_9',\n",
    "                        'FLAG_DOCUMENT_10',\n",
    "                        'FLAG_DOCUMENT_11',\n",
    "                        'FLAG_DOCUMENT_12',\n",
    "                        'FLAG_DOCUMENT_13',\n",
    "                        'FLAG_DOCUMENT_14',\n",
    "                        'FLAG_DOCUMENT_15',\n",
    "                        'FLAG_DOCUMENT_16',\n",
    "                        'FLAG_DOCUMENT_17',\n",
    "                        'FLAG_DOCUMENT_18',\n",
    "                        'FLAG_DOCUMENT_19',\n",
    "                        'FLAG_DOCUMENT_20',\n",
    "                        'FLAG_DOCUMENT_21']]\n",
    "train['FLAG_DOCUMENT_SUM'] = TRAIN_FLAG_SUM.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PHONE_SUM = train[[\n",
    "    'FLAG_MOBIL',\n",
    "    'FLAG_EMP_PHONE',\n",
    "    'FLAG_WORK_PHONE',\n",
    "    'FLAG_CONT_MOBILE',\n",
    "    'FLAG_PHONE']]\n",
    "train['PHONE_SUM'] = TRAIN_PHONE_SUM.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(actual, predicted):\n",
    "    actual = np.log(actual)\n",
    "    predicted = np.log(predicted)\n",
    "    return np.sqrt(np.sum(np.square(actual-predicted))/len(actual))\n",
    "\n",
    "def log_transform(feature):\n",
    "    train[feature] = np.log1p(train[feature].values)\n",
    "\n",
    "def quadratic(feature):\n",
    "    train[feature+'2'] = train[feature]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_transform('AMT_CREDIT')\n",
    "log_transform('AMT_ANNUITY')\n",
    "log_transform('AMT_GOODS_PRICE')\n",
    "log_transform('AMT_INCOME_TOTAL')\n",
    "\n",
    "train['NAME_CONTRACT_TYPE'] = train['NAME_CONTRACT_TYPE'].apply(lambda x: 1 if x =='Cash loans' else 0)\n",
    "train['FLAG_OWN_CAR'] = train['FLAG_OWN_CAR'].apply(lambda x: 1 if x == 'y' else 0)\n",
    "train['AMT_INCOME_TOTAL'] = train['AMT_INCOME_TOTAL'].apply(lambda x: 1 if x > 13.3 else 0)\n",
    "\n",
    "def func_NAME_EDUCATION_TYPE(x):\n",
    "    if x in ('Higher education', 'Academic degree'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "train['NAME_EDUCATION_TYPE'] = train['NAME_EDUCATION_TYPE'].apply(func_NAME_EDUCATION_TYPE)\n",
    "\n",
    "def func_NAME_HOUSING_TYPE(x):\n",
    "    if x in ('Maternity leave', 'Unemployede'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "train['NAME_HOUSING_TYPE'] = train['NAME_HOUSING_TYPE'].apply(func_NAME_HOUSING_TYPE)\n",
    "\n",
    "train['REGION_POPULATION_RELATIVE'] = train['REGION_POPULATION_RELATIVE'].apply(lambda x: 1 if x >= 0.02 else 0)\n",
    "train['OWN_CAR_AGE'] = train['OWN_CAR_AGE'].apply(lambda x: 1 if x <= 10 else 0)\n",
    "\n",
    "train['ORGANIZATION_spmean'] = train[['ORGANIZATION_TYPE', 'TARGET']].groupby(['ORGANIZATION_TYPE']).mean()['TARGET']\n",
    "train['ORGANIZATION_TYPE'] = train['ORGANIZATION_spmean'].apply(lambda x: 1 if x > 0.08 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['APARTMENTS_MEDI',\n",
    "                            'BASEMENTAREA_MEDI',\n",
    "                            'YEARS_BEGINEXPLUATATION_MEDI',\n",
    "                            'YEARS_BUILD_MEDI',\n",
    "                            'COMMONAREA_MEDI',\n",
    "                            'ELEVATORS_MEDI',\n",
    "                            'ENTRANCES_MEDI',\n",
    "                            'FLOORSMAX_MEDI',\n",
    "                            'FLOORSMIN_MEDI',\n",
    "                            'LANDAREA_MEDI',\n",
    "                            'LIVINGAPARTMENTS_MEDI',\n",
    "                            'LIVINGAREA_MEDI',\n",
    "                            'NONLIVINGAPARTMENTS_MEDI',\n",
    "                            'NONLIVINGAREA_MEDI',\n",
    "                            'APARTMENTS_MODE',\n",
    "                            'BASEMENTAREA_MODE',\n",
    "                            'YEARS_BEGINEXPLUATATION_MODE',\n",
    "                            'YEARS_BUILD_MODE',\n",
    "                            'COMMONAREA_MODE',\n",
    "                            'ELEVATORS_MODE',\n",
    "                            'ENTRANCES_MODE',\n",
    "                            'FLOORSMAX_MODE',\n",
    "                            'FLOORSMIN_MODE',\n",
    "                            'LANDAREA_MODE',\n",
    "                            'LIVINGAPARTMENTS_MODE',\n",
    "                            'LIVINGAREA_MODE',\n",
    "                            'NONLIVINGAPARTMENTS_MODE',\n",
    "                            'NONLIVINGAREA_MODE',\n",
    "                            'FONDKAPREMONT_MODE',\n",
    "                            'HOUSETYPE_MODE',\n",
    "                            'TOTALAREA_MODE',\n",
    "                            'WALLSMATERIAL_MODE',\n",
    "                            'EMERGENCYSTATE_MODE',\n",
    "                            'APARTMENTS_AVG',\n",
    "                            'BASEMENTAREA_AVG',\n",
    "                            'YEARS_BEGINEXPLUATATION_AVG',\n",
    "                            'YEARS_BUILD_AVG',\n",
    "                            'COMMONAREA_AVG',\n",
    "                            'ELEVATORS_AVG',\n",
    "                            'ENTRANCES_AVG',\n",
    "                            'FLOORSMAX_AVG',\n",
    "                            'FLOORSMIN_AVG',\n",
    "                            'LANDAREA_AVG',\n",
    "                            'LIVINGAPARTMENTS_AVG',\n",
    "                            'LIVINGAREA_AVG',\n",
    "                            'NONLIVINGAPARTMENTS_AVG',\n",
    "                            'NONLIVINGAREA_AVG'\n",
    "                            ,\n",
    "                            'FLAG_DOCUMENT_2',\n",
    "                            'FLAG_DOCUMENT_3',\n",
    "                            'FLAG_DOCUMENT_4',\n",
    "                            'FLAG_DOCUMENT_5',\n",
    "                            'FLAG_DOCUMENT_6',\n",
    "                            'FLAG_DOCUMENT_7',\n",
    "                            'FLAG_DOCUMENT_8',\n",
    "                            'FLAG_DOCUMENT_9',\n",
    "                            'FLAG_DOCUMENT_10',\n",
    "                            'FLAG_DOCUMENT_11',\n",
    "                            'FLAG_DOCUMENT_12',\n",
    "                            'FLAG_DOCUMENT_13',\n",
    "                            'FLAG_DOCUMENT_14',\n",
    "                            'FLAG_DOCUMENT_15',\n",
    "                            'FLAG_DOCUMENT_16',\n",
    "                            'FLAG_DOCUMENT_17',\n",
    "                            'FLAG_DOCUMENT_18',\n",
    "                            'FLAG_DOCUMENT_19',\n",
    "                            'FLAG_DOCUMENT_20',\n",
    "                            'FLAG_DOCUMENT_21',\n",
    "                            'FLAG_MOBIL',\n",
    "                            'FLAG_EMP_PHONE',\n",
    "                            'FLAG_WORK_PHONE',\n",
    "                            'FLAG_CONT_MOBILE',\n",
    "                            'FLAG_PHONE'\n",
    "                            ,\n",
    "                            'ORGANIZATION_spmean'\n",
    "                            ,\n",
    "                            'SK_ID_CURR'\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [f for f in train.columns if train.dtypes[f] != 'object']\n",
    "numerical.remove('TARGET')\n",
    "categorical = [f for f in train.columns if train.dtypes[f] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical:\n",
    "    train[c] = train[c].astype('category')\n",
    "    if train[c].isnull().any():\n",
    "        train[c] = train[c].cat.add_categories(['MISSING'])\n",
    "        train[c] = train[c].fillna('MISSING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(frame, feature):\n",
    "    ordering = pd.DataFrame()\n",
    "    ordering['val'] = frame[feature].unique()\n",
    "    ordering.index = ordering.val\n",
    "    # ordering['spmean'] = frame[[feature, 'TARGET']].groupby(feature).mean()['TARGET']\n",
    "    # ordering = ordering.sort_values('spmean')\n",
    "    ordering['ordering'] = range(1, ordering.shape[0]+1)\n",
    "    ordering = ordering['ordering'].to_dict()\n",
    "\n",
    "    for cat, o in ordering.items():\n",
    "        frame.loc[frame[feature] == cat, feature+'_E'] = o\n",
    "\n",
    "cate_encoded = []\n",
    "for q in categorical:\n",
    "    encode(train, q)\n",
    "    encode(test, q)\n",
    "    cate_encoded.append(q+'_E')\n",
    "# print(cate_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42, )\n",
    "for train_index, test_index in split.split(train, train[\"NAME_INCOME_TYPE\"]):\n",
    "    train_set = train.loc[train_index]\n",
    "    test_set = train.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = numerical + cate_encoded\n",
    "# X_train = train[features].fillna(0.).values\n",
    "# y_train = train['TARGET'].values\n",
    "# X_test = test[features].fillna(0.).values\n",
    "\n",
    "\n",
    "X_train = train_set[features].fillna(0.).values\n",
    "y_train = train_set['TARGET'].values\n",
    "X_test = test_set[features].fillna(0.).values\n",
    "y_test = test_set['TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# logreg = LogisticRegression()\n",
    "# logreg.fit(X_resampled, y_resampled) \n",
    "# y_pred = logreg.predict_proba(X_test)[:,1]\n",
    "# roc_auc_score(y_test, y_pred) # 0.6373158605096496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_10 = LogisticRegression(C=10)\n",
    "# logreg_10.fit(X_resampled, y_resampled)\n",
    "# y_pred_10 = logreg_10.predict_proba(X_test)[:,1]\n",
    "# roc_auc_score(y_test, y_pred_10) # 0.6221440069544937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6325535127299906"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_0_1 = LogisticRegression(C=0.1)\n",
    "logreg_0_1.fit(X_resampled, y_resampled)\n",
    "y_pred_0_1 = logreg_0_1.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, y_pred_0_1) # 0.6607293666286557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_00_1 = LogisticRegression(C=0.01)\n",
    "# logreg_00_1.fit(X_resampled, y_resampled)\n",
    "# y_pred_00_1 = logreg_00_1.predict_proba(X_test)[:,1]\n",
    "# roc_auc_score(y_test, y_pred_00_1) # 0.658615496478248\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6832749406941135"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
    "rf.fit(X_train, y_train)            # 0.7190124215159207\n",
    "# rf.fit(X_resampled, y_resampled)  # 0.6841750535878548 \n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred_rf) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n1. feature 44 (0.151524)\n2. feature 30 (0.094911)\n3. feature 8 (0.093183)\n4. feature 10 (0.088280)\n5. feature 29 (0.071331)\n6. feature 25 (0.064045)\n7. feature 15 (0.061227)\n8. feature 31 (0.052512)\n9. feature 33 (0.043026)\n10. feature 18 (0.033106)\n11. feature 41 (0.032314)\n12. feature 47 (0.032179)\n13. feature 26 (0.030855)\n14. feature 19 (0.029111)\n15. feature 45 (0.025792)\n16. feature 43 (0.015207)\n17. feature 17 (0.013287)\n18. feature 50 (0.010965)\n19. feature 28 (0.010716)\n20. feature 3 (0.009622)\n21. feature 24 (0.007029)\n22. feature 32 (0.006869)\n23. feature 49 (0.004867)\n24. feature 42 (0.004544)\n25. feature 1 (0.003758)\n26. feature 48 (0.003414)\n27. feature 34 (0.002043)\n28. feature 7 (0.001702)\n29. feature 22 (0.000591)\n30. feature 23 (0.000541)\n31. feature 5 (0.000440)\n32. feature 35 (0.000329)\n33. feature 16 (0.000220)\n34. feature 20 (0.000216)\n35. feature 46 (0.000145)\n36. feature 40 (0.000081)\n37. feature 11 (0.000022)\n38. feature 14 (0.000000)\n39. feature 13 (0.000000)\n40. feature 12 (0.000000)\n41. feature 38 (0.000000)\n42. feature 9 (0.000000)\n43. feature 39 (0.000000)\n44. feature 21 (0.000000)\n45. feature 6 (0.000000)\n46. feature 37 (0.000000)\n47. feature 4 (0.000000)\n48. feature 27 (0.000000)\n49. feature 2 (0.000000)\n50. feature 36 (0.000000)\n51. feature 0 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7211824305608072"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)           # 0.7211824305608072\n",
    "lda.fit(X_resampled, y_resampled)   # 0.7209399233541647\n",
    "y_pred_lda = lda.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, y_pred_lda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5799225915230429"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda =QDA()\n",
    "qda.fit(X_train, y_train)           # 0.5799225915230429\n",
    "# qda.fit(X_resampled, y_resampled) # 0.6193209887224465\n",
    "y_pred_qda = qda.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, y_pred_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# svc = SVC(random_state=0, probability=True)\n",
    "# # svc.fit(X_train, y_train)\n",
    "# svc.fit(X_resampled, y_resampled)\n",
    "# y_pred_svc = svc.predict_proba(X_test)[:, 1]\n",
    "# roc_auc_score(y_test, y_pred_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7082597786530709"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from brew.base import Ensemble, EnsembleClassifier\n",
    "from brew.stacking.stacker import EnsembleStack, EnsembleStackClassifier\n",
    "from brew.combination.combiner import Combiner\n",
    "\n",
    "# Creating Ensemble\n",
    "ensemble = Ensemble([logreg_0_1, rf, lda])\n",
    "eclf = EnsembleClassifier(ensemble=ensemble, combiner=Combiner('mean'))\n",
    "\n",
    "# eclf.fit(X_resampled, y_resampled) # 0.7175472150622211\n",
    "eclf.fit(X_train, y_train)           # 0.7082597786530709\n",
    "y_pred_ensemble = eclf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred_ensemble)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7247774845417322"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Stacking\n",
    "layer_1 = Ensemble([logreg_0_1, rf, lda])\n",
    "layer_2 = Ensemble([sklearn.clone(logreg_0_1)])\n",
    "stack = EnsembleStack(cv=3)\n",
    "stack.add_layer(layer_1)\n",
    "stack.add_layer(layer_2)\n",
    "\n",
    "sclf = EnsembleStackClassifier(stack)\n",
    "\n",
    "# sclf.fit(X_resampled, y_resampled) # 0.6557789148329445\n",
    "sclf.fit(X_train, y_train)           # 0.7247774845417322\n",
    "y_pred_stack = sclf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred_stack)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.700379\tvalid_0's l2: 0.0738693\nTraining until validation scores don't improve for 5 rounds.\n[2]\tvalid_0's auc: 0.716268\tvalid_0's l2: 0.073691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\tvalid_0's auc: 0.718226\tvalid_0's l2: 0.0734266\n[4]\tvalid_0's auc: 0.722806\tvalid_0's l2: 0.073111\n[5]\tvalid_0's auc: 0.72497\tvalid_0's l2: 0.0728113\n[6]\tvalid_0's auc: 0.724578\tvalid_0's l2: 0.0725492\n[7]\tvalid_0's auc: 0.724426\tvalid_0's l2: 0.0723091\n[8]\tvalid_0's auc: 0.724563\tvalid_0's l2: 0.0720812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\tvalid_0's auc: 0.724327\tvalid_0's l2: 0.0718823\n[10]\tvalid_0's auc: 0.725367\tvalid_0's l2: 0.0717242\n[11]\tvalid_0's auc: 0.725559\tvalid_0's l2: 0.07155\n[12]\tvalid_0's auc: 0.727919\tvalid_0's l2: 0.0714469\n[13]\tvalid_0's auc: 0.728134\tvalid_0's l2: 0.0712896\n[14]\tvalid_0's auc: 0.728355\tvalid_0's l2: 0.0711481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\tvalid_0's auc: 0.728629\tvalid_0's l2: 0.0710039\n[16]\tvalid_0's auc: 0.729219\tvalid_0's l2: 0.0708939\n[17]\tvalid_0's auc: 0.730231\tvalid_0's l2: 0.070791\n[18]\tvalid_0's auc: 0.730428\tvalid_0's l2: 0.0706768\n[19]\tvalid_0's auc: 0.730615\tvalid_0's l2: 0.0705705\n[20]\tvalid_0's auc: 0.731005\tvalid_0's l2: 0.0704654\nDid not meet early stopping. Best iteration is:\n[20]\tvalid_0's auc: 0.731005\tvalid_0's l2: 0.0704654\nSave model...\nStart predicting...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7310050369948817"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# create dataset for lightgbm\n",
    "# lgb_train = lgb.Dataset(X_resampled, y_resampled) # 0.7032034257774565\n",
    "lgb_train = lgb.Dataset(X_train, y_train)           # 0.7310050369948817\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "print('Save model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred_gbm = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "roc_auc_score(y_test, y_pred_gbm) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7458267768231585"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier( DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "# ada_clf.fit(X_resampled, y_resampled) # 0.7121451170928985\n",
    "ada_clf.fit(X_train, y_train)           # 0.7458267768231585\n",
    "y_pred_ada = ada_clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred_ada)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6811196557588269"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# gbrt = GradientBoostingClassifier(max_depth=1, random_state=0).fit(X_train, y_train)          # 0.7257854798881231\n",
    "gbrt = GradientBoostingClassifier(max_depth=1, random_state=0).fit(X_resampled, y_resampled)    # 0.6811196557588269\n",
    "y_pred_gbrt = gbrt.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred_gbrt)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'SK_ID_CURR': test.SK_ID_CURR, 'TARGET': y_pred})\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
